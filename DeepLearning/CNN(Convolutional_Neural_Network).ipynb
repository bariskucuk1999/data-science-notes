{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN(Convolutional Neural Network).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPxEAZLrpnIATK0eoz+eKdL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bariskucuk1999/data-science-notes/blob/main/CNN(Convolutional_Neural_Network).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_XwF9NuMBUE"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "görselleri bölerek filtreleme işlemi\n",
        "convolution(evrişim): 3x3 matriste diyagonaller artı, diğerleri eksi\n",
        "pooling(havuzlama): 2x2 matriste max değeri alma(görseli küçültme gibi)\n",
        "flattening(düzleştirme): matrisi düz bir hale getirerek giriş katmanına uygun duruma(bağlanabilir) getirme\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/27CNN_Cinsiyet.zip"
      ],
      "metadata": {
        "id": "gGPmOgUkfYD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras==2.3.1 \n",
        "!pip install tensorflow==1.14.0"
      ],
      "metadata": {
        "id": "hXWatkeKggU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "# ilkleme\n",
        "classifier = Sequential()\n",
        "\n",
        "# Adım 1 - Convolution\n",
        "classifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))\n",
        "\n",
        "# Adım 2 - Pooling\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# 2. convolution katmanı\n",
        "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Adım 3 - Flattening\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Adım 4 - YSA(yapay sinir ağı)\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "# CNN\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# CNN ve resimler\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/27CNN_Cinsiyet/veriler/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 1,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/27CNN_Cinsiyet/veriler/training_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 1,\n",
        "                                            class_mode = 'binary')\n",
        "\n",
        "classifier.fit_generator(training_set,\n",
        "                         steps_per_epoch = 8000,\n",
        "                         epochs = 1,\n",
        "                         validation_data = test_set,\n",
        "                         validation_steps = 2000)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "test_set.reset()\n",
        "pred=classifier.predict_generator(test_set,verbose=1)\n",
        "#pred = list(map(round,pred))\n",
        "pred[pred > .5] = 1\n",
        "pred[pred <= .5] = 0\n",
        "\n",
        "print('prediction gecti')\n",
        "labels = (training_set.class_indices)\n",
        "\n",
        "test_labels = []\n",
        "\n",
        "for i in range(0,int(203)):\n",
        "    test_labels.extend(np.array(test_set[i][1]))\n",
        "    \n",
        "print('test_labels')\n",
        "print(test_labels)\n",
        "\n",
        "#labels = (training_set.class_indices)\n",
        "\n",
        "idx = []  \n",
        "for i in test_set:\n",
        "    ixx = (test_set.batch_index - 1) * test_set.batch_size\n",
        "    ixx = test_set.filenames[ixx : ixx + test_set.batch_size]\n",
        "    idx.append(ixx)\n",
        "    print(i)\n",
        "    print(idx)\n",
        "\n",
        "dosyaisimleri = test_set.filenames\n",
        "abc = test_set\n",
        "print(idx)\n",
        "test_labels = test_set\n",
        "sonuc = pd.DataFrame()\n",
        "sonuc['dosyaisimleri']= dosyaisimleri\n",
        "sonuc['tahminler'] = pred\n",
        "sonuc['test'] = test_labels   \n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "cm = confusion_matrix(test_labels, pred)\n",
        "print (cm)\n"
      ],
      "metadata": {
        "id": "W5qDImwQSBeR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
